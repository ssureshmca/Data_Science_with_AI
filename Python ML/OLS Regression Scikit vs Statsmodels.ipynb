{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "320f2c73",
   "metadata": {},
   "source": [
    "When it comes to performing linear regression in Python, there are two popular libraries that come to mind: Scikit-learn and Statsmodels. Both have their own strengths and weaknesses, and in this article, we will compare the two libraries specifically for ordinary least squares (OLS) regression.\n",
    "\n",
    "**What is OLS Regression?**\n",
    "\n",
    "Before diving into the comparison, let’s first define what OLS regression is. OLS regression is a method used to estimate the relationship between a dependent variable and one or more independent variables. It assumes that the relationship between the variables is linear and that the errors in the model are normally distributed and have constant variance.\n",
    "\n",
    "The goal of OLS regression is to find the coefficients that minimize the sum of the squared errors between the predicted values and the actual values. Once these coefficients are found, they can be used to make predictions on new data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f319e2",
   "metadata": {},
   "source": [
    "### Scikit-learn\n",
    "\n",
    "Scikit-learn is a popular machine learning library in Python that provides a wide range of tools for data analysis and modeling. It includes a variety of regression models, including OLS regression.\n",
    "\n",
    "One of the main benefits of using Scikit-learn for OLS regression is its simplicity. The library provides a simple API that makes it easy to fit a linear regression model and make predictions. Here’s an example of how to perform OLS regression using Scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6d9ad71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "california = fetch_california_housing()\n",
    "X = california.data\n",
    "y = california.target\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "predictions = model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb920026",
   "metadata": {},
   "source": [
    "In this example, we load the california_housing dataset and split it into the features X and the target variable y. We then create an instance of the LinearRegression class, fit the model on the data, and make predictions on the same data.\n",
    "\n",
    "While Scikit-learn makes it easy to perform OLS regression, it does have some limitations. \n",
    "\n",
    "For example, it doesn’t provide as much statistical information about the model as Statsmodels does. \n",
    "\n",
    "Additionally, it doesn’t provide as many options for diagnostic tests such as checking for heteroscedasticity or multicollinearity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6ce002",
   "metadata": {},
   "source": [
    "### Statsmodels\n",
    "\n",
    "Statsmodels is a library in Python that provides a wide range of statistical tools for data analysis. It includes a variety of regression models, including OLS regression.\n",
    "\n",
    "One of the main benefits of using Statsmodels for OLS regression is the amount of statistical information it provides. For example, it provides a summary of the model that includes information such as the R-squared value, standard errors of the coefficients, and p-values. Here’s an example of how to perform OLS regression using Statsmodels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8373d08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.606\n",
      "Model:                            OLS   Adj. R-squared:                  0.606\n",
      "Method:                 Least Squares   F-statistic:                     3970.\n",
      "Date:                Fri, 06 Oct 2023   Prob (F-statistic):               0.00\n",
      "Time:                        11:35:15   Log-Likelihood:                -22624.\n",
      "No. Observations:               20640   AIC:                         4.527e+04\n",
      "Df Residuals:                   20631   BIC:                         4.534e+04\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        -36.9419      0.659    -56.067      0.000     -38.233     -35.650\n",
      "x1             0.4367      0.004    104.054      0.000       0.428       0.445\n",
      "x2             0.0094      0.000     21.143      0.000       0.009       0.010\n",
      "x3            -0.1073      0.006    -18.235      0.000      -0.119      -0.096\n",
      "x4             0.6451      0.028     22.928      0.000       0.590       0.700\n",
      "x5         -3.976e-06   4.75e-06     -0.837      0.402   -1.33e-05    5.33e-06\n",
      "x6            -0.0038      0.000     -7.769      0.000      -0.005      -0.003\n",
      "x7            -0.4213      0.007    -58.541      0.000      -0.435      -0.407\n",
      "x8            -0.4345      0.008    -57.682      0.000      -0.449      -0.420\n",
      "==============================================================================\n",
      "Omnibus:                     4393.650   Durbin-Watson:                   0.885\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            14087.596\n",
      "Skew:                           1.082   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.420   Cond. No.                     2.38e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.38e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "california = fetch_california_housing()\n",
    "X = california.data\n",
    "y = california.target\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fce0651",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
